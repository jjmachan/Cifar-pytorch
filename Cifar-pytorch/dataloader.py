# AUTOGENERATED! DO NOT EDIT! File to edit: 01_dataloader.ipynb (unless otherwise specified).

__all__ = ['unpickle_cifar', 'load_label_names', 'normalize', 'one_hot_encoding', 'CifarDownloadedDataset']

# Cell

import torch
import torchvision
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset

# Cell
# py fun to load data
def unpickle_cifar(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

# Cell
def load_label_names():
    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']


# Cell
def normalize(x):
    min_val = np.min(x)
    max_val = np.max(x)
    x = (x - min_val) / (max_val - min_val)
    return x

# Cell

def one_hot_encoding(labels):
    encoded = np.zeros((len(labels), 10))

    for idx,val in enumerate(labels):
        encoded[idx][val] = 1
    return encoded



# Cell

class CifarDownloadedDataset(Dataset):
    """
    This is the Cifar10 dataset loader from the downloaded section.
    """

    def __init__(self, root_dir, train=True, transform=None):
        """
        Args:
            root_dir (string): Path of the cifar10 data_batches.
            transforms (callable, optional): Optional transforms to
                be applied on a sample.
        """

        self.root_dir = Path(root_dir)
        self.transform = transform
        self.train_batches = ['data_batch_5',
                              'data_batch_4',
                              'data_batch_1',
                              'data_batch_3',
                              'data_batch_2',]
        self.test_batches = ['test_batch']

        self.labels = []
        self.data = np.empty((0,3072), np.uint8)

        cifar_data = dict()

        if train:
            data_batches=self.train_batches
        else:
            data_batches=self.test_batches

        for batch_file in data_batches:
            cifar_data[batch_file] = unpickle_cifar(dataPath/batch_file)

        for batch in cifar_data:
            print('appending: ',batch)
            image_batch = cifar_data[batch][b'data']
            self.data = np.append(self.data, image_batch, axis=0)
            label_batch = cifar_data[batch][b'labels']
            self.labels += label_batch

    def __len__(self):
        return self.data.shape[0]

    def __getitem(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        cifar_data = dict()
        for batch_file in self.train_batches:
            cifar_data[batch_file] = unpickle_cifar(dataPath/batch_file)

